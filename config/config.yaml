# Database
database:
  schema_path: "data/db_schema.json"
  selected_aliases: ["A", "AI", "PC", "ISC", "II", "PCOZ", "OZ", "OV"]

# Paths
paths:
  data_raw: "data/raw/"
  data_processed: "data/processed/"
  models: "models/"
  logs: "logs/"

# Target e colonne
target:
  column: "AI_Prezzo_Ridistribuito"

# Preprocessing parametri
preprocessing:
  # Temporal split per evitare data leakage temporale
  use_temporal_split: true
  date_column: "A_AnnoStipula"  # Colonna data per split temporale
  
  # Soglie correlazione
  cramer_threshold: 0.95
  corr_threshold: 0.95
  
  # Encoding
  low_cardinality_threshold: 10
  high_cardinality_max: 100
  
  # Outliers - MIGLIORATO: Stratificazione per categoria
  outlier_strategy: "category_stratified"  # "global" | "category_stratified"
  category_column: "AI_IdCategoriaCatastale"  # Colonna per stratificazione
  alternative_category_column: "CC_Id"  # Fallback se prima non disponibile
  
  # Parametri outlier detection per categoria
  z_threshold: 2.5
  iqr_multiplier: 1.5
  isolation_contamination: 0.05
  min_methods_outlier: 2
  min_samples_per_category: 30  # Minimo campioni per fare detection
  
  # Parametri fallback globale (se categoria non disponibile)
  global_z_threshold: 3.0
  global_iqr_multiplier: 1.5
  global_isolation_contamination: 0.1
  
  # PCA - CORRETTA gestione variance threshold
  use_pca: false
  pca_variance_threshold: 0.95  # 0-1 per % varianza, >1 per num componenti fisso
  
  # Split
  test_size: 0.2
  val_size: 0.2
  random_state: 42
  
  # Stratificazione split (per target continuo) - DISABILITATA per temporal split
  use_stratified_split: false  # Incompatibile con temporal split
  stratification_quantiles: 5  # Divide target in 5 quantili per stratificazione

# Training parametri
training:
  # Cross-validation - MIGLIORATA per temporal data
  cv_folds: 5
  cv_scoring: 'neg_root_mean_squared_error'
  use_time_series_cv: true  # Usa TimeSeriesSplit invece di KFold per temporal data
  
  # Optuna optimization
  n_trials: 100
  optuna_timeout: 7200  # 2 ore in secondi
  optuna_pruning_percentile: 25
  
  # Parallelization
  n_jobs: -1
  
  # Random state
  random_state: 42

# Modelli da addestrare
models:
  # Baseline models (sempre abilitati)
  baseline:
    linear_regression: true
    ridge: true
    lasso: true
    elastic_net: true
    decision_tree: true
    knn: true
    svr: true
  
  # Advanced models (con ottimizzazione Optuna)
  advanced:
    random_forest: true
    gradient_boosting: true
    xgboost: true
    catboost: true
    lightgbm: true
    hist_gradient_boosting: true
  
  # Ensemble models
  ensemble:
    voting_regressor: true
    stacking_regressor: true

# Ottimizzazione iperparametri
tuning:
  enabled: true
  n_trials: 100
  timeout: 3600  # 1 ora
  
# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/pipeline.log"

# Esecuzione pipeline
execution:
  steps:
    - retrieve_data
    - build_dataset
    - preprocessing
    - training
    - evaluation
  
  force_reload: true  # Cambiato da true per evitare reload continuo

# Validation e monitoring
validation:
  # Analisi outliers post-detection
  generate_outlier_analysis: true
  outlier_analysis_plots: true
  
  # Performance monitoring per categoria
  category_performance_analysis: true
  min_samples_category_analysis: 50
  
  # Residual analysis
  residual_analysis: true
  residual_plots: true

# Quality checks - AGGIUNTI controlli data leakage
quality_checks:
  # Verifica data leakage
  check_temporal_leakage: true
  check_target_leakage: true
  
  # Verifica distribuzione categorie tra split
  check_category_distribution: true
  max_category_drift: 0.05  # Max differenza % tra train/val/test
  
  # Feature stability
  check_feature_stability: true
  max_feature_drift: 0.1
  
  # NUOVI: Controlli specifici per temporal split
  validate_temporal_split: true
  min_temporal_gap_days: 30  # Minimo gap temporale tra train/val/test
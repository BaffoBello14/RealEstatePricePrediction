# Configurazione globale del progetto ML

# Database
database:
  schema_path: "data/db_schema.json"
  selected_aliases: ["A", "AI", "PC", "ISC", "II", "PCOZ", "OZ", "OV"]

# Paths
paths:
  data_raw: "data/raw/"
  data_processed: "data/processed/"
  models: "models/"
  logs: "logs/"

# Target e colonne
target:
  column: "AI_Prezzo_Ridistribuito"

# Preprocessing parametri
preprocessing:
  # Soglie correlazione
  cramer_threshold: 0.95
  corr_threshold: 0.95
  
  # Encoding
  low_cardinality_threshold: 10
  high_cardinality_max: 100
  
  # Outliers
  z_threshold: 3
  iqr_multiplier: 1.5
  isolation_contamination: 0.1
  min_methods_outlier: 2
  
  # PCA
  use_pca: false
  pca_variance_threshold: 0.95
  
  # Split
  test_size: 0.2
  val_size: 0.2
  random_state: 42

# Training parametri
training:
  # Cross-validation
  cv_folds: 5
  cv_scoring: 'neg_root_mean_squared_error'
  
  # Optuna optimization
  n_trials: 100
  optuna_timeout: 7200  # 2 ore in secondi
  optuna_pruning_percentile: 25
  
  # Parallelization
  n_jobs: -1
  
  # Random state
  random_state: 42

# Modelli da addestrare
models:
  # Baseline models (sempre abilitati)
  baseline:
    linear_regression: true
    ridge: true
    lasso: true
    elastic_net: true
    decision_tree: true
    knn: true
    svr: true
  
  # Advanced models (con ottimizzazione Optuna)
  advanced:
    random_forest: true
    gradient_boosting: true
    xgboost: true
    catboost: true
    lightgbm: true
    hist_gradient_boosting: true
  
  # Ensemble models
  ensemble:
    voting_regressor: true
    stacking_regressor: true

# Ottimizzazione iperparametri
tuning:
  enabled: true
  n_trials: 100
  timeout: 3600  # 1 ora
  
# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/pipeline.log"

# Esecuzione pipeline
execution:
  steps:
    - retrieve_data
    - build_dataset
    - preprocessing
    - training
    - evaluation
  
  force_reload: true  # Se True, rigenera tutto da capo